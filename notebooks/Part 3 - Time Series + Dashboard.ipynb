{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbbc8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef193727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns #visualisation\n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "%matplotlib inline\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "import statistics as stats\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a310010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset without a header and assign column names\n",
    "df_tweets = pd.read_csv('processed_tweets_with_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c0ed0ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>raw_sentiment</th>\n",
       "      <th>raw_sentiment_classification</th>\n",
       "      <th>processed_sentiment</th>\n",
       "      <th>processed_sentiment_classification</th>\n",
       "      <th>sentiment_difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-04-06 22:19:45</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot http awww bummer shoulda got david ...</td>\n",
       "      <td>-0.0173</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.3645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-04-06 22:19:49</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset ca update facebook texting might cry res...</td>\n",
       "      <td>-0.7500</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.7269</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.0231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2009-04-06 22:19:53</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dived many time ball managed save 50 ...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2009-04-06 22:19:57</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behaving mad ca see</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 date  \\\n",
       "0           0  2009-04-06 22:19:45   \n",
       "1           1  2009-04-06 22:19:49   \n",
       "2           2  2009-04-06 22:19:53   \n",
       "3           3  2009-04-06 22:19:57   \n",
       "4           4  2009-04-06 22:19:57   \n",
       "\n",
       "                                                text  \\\n",
       "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1  is upset that he can't update his Facebook by ...   \n",
       "2  @Kenichan I dived many times for the ball. Man...   \n",
       "3    my whole body feels itchy and like its on fire    \n",
       "4  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                      processed_text  raw_sentiment  \\\n",
       "0  switchfoot http awww bummer shoulda got david ...        -0.0173   \n",
       "1  upset ca update facebook texting might cry res...        -0.7500   \n",
       "2  kenichan dived many time ball managed save 50 ...         0.4939   \n",
       "3                    whole body feel itchy like fire        -0.2500   \n",
       "4                nationwideclass behaving mad ca see        -0.4939   \n",
       "\n",
       "  raw_sentiment_classification  processed_sentiment  \\\n",
       "0                     Negative              -0.3818   \n",
       "1                     Negative              -0.7269   \n",
       "2                     Negative               0.4939   \n",
       "3                     Negative              -0.2500   \n",
       "4                     Negative              -0.4939   \n",
       "\n",
       "  processed_sentiment_classification  sentiment_difference  \n",
       "0                           Negative                0.3645  \n",
       "1                           Negative               -0.0231  \n",
       "2                           Negative                0.0000  \n",
       "3                           Negative                0.0000  \n",
       "4                           Negative                0.0000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the dataset was uploaded correctly\n",
    "df_tweets.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6b54465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                              int64\n",
       "date                                   object\n",
       "text                                   object\n",
       "processed_text                         object\n",
       "raw_sentiment                         float64\n",
       "raw_sentiment_classification           object\n",
       "processed_sentiment                   float64\n",
       "processed_sentiment_classification     object\n",
       "sentiment_difference                  float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the types of data\n",
    "df_tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a20ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "# Convert 'date' column to datetime and set as index\n",
    "df_tweets['date'] = pd.to_datetime(df_tweets['date'])\n",
    "df_tweets.set_index('date', inplace=True)\n",
    "series = df_tweets['raw_sentiment'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "960b7dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                              int64\n",
       "text                                   object\n",
       "processed_text                         object\n",
       "raw_sentiment                         float64\n",
       "raw_sentiment_classification           object\n",
       "processed_sentiment                   float64\n",
       "processed_sentiment_classification     object\n",
       "sentiment_difference                  float64\n",
       "raw_sentiment_negative                  int64\n",
       "raw_sentiment_positive                  int64\n",
       "processed_sentiment_negative            int64\n",
       "processed_sentiment_positive            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the types of data\n",
    "df_tweets.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a4f2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate model\n",
    "def evaluate_forecast(actual, predicted):\n",
    "    mse = mean_squared_error(actual, predicted)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ad3e6d",
   "metadata": {},
   "source": [
    "## Arima Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff35b0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it is not monotonic and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:836: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "# ARIMA Model\n",
    "arima_model = ARIMA(series, order=(5,1,0))\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "arima_forecast_1 = arima_result.forecast(steps=1)\n",
    "arima_rmse_1 = evaluate_forecast(series[-1:], arima_forecast_1)\n",
    "\n",
    "arima_forecast_3 = arima_result.forecast(steps=3)\n",
    "arima_rmse_3 = evaluate_forecast(series[-3:], arima_forecast_3)\n",
    "\n",
    "arima_forecast_7 = arima_result.forecast(steps=7)\n",
    "arima_rmse_7 = evaluate_forecast(series[-7:], arima_forecast_7)\n",
    "\n",
    "arima_forecast_28 = arima_result.forecast(steps=28)\n",
    "arima_rmse_28 = evaluate_forecast(series[-28:], arima_forecast_28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c331e552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000    0.563919\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_forecast_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca7d8e82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000    0.563919\n",
       "1600001    0.525923\n",
       "1600002    0.522974\n",
       "Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_forecast_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4912efc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000    0.563919\n",
       "1600001    0.525923\n",
       "1600002    0.522974\n",
       "1600003    0.537465\n",
       "1600004    0.566669\n",
       "1600005    0.548205\n",
       "1600006    0.544218\n",
       "Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_forecast_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb493eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000    0.563919\n",
       "1600001    0.525923\n",
       "1600002    0.522974\n",
       "1600003    0.537465\n",
       "1600004    0.566669\n",
       "1600005    0.548205\n",
       "1600006    0.544218\n",
       "1600007    0.540897\n",
       "1600008    0.543384\n",
       "1600009    0.546813\n",
       "1600010    0.548359\n",
       "1600011    0.545322\n",
       "1600012    0.544833\n",
       "1600013    0.544931\n",
       "1600014    0.545605\n",
       "1600015    0.545978\n",
       "1600016    0.545838\n",
       "1600017    0.545419\n",
       "1600018    0.545434\n",
       "1600019    0.545534\n",
       "1600020    0.545635\n",
       "1600021    0.545640\n",
       "1600022    0.545583\n",
       "1600023    0.545541\n",
       "1600024    0.545561\n",
       "1600025    0.545582\n",
       "1600026    0.545590\n",
       "1600027    0.545583\n",
       "Name: predicted_mean, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arima_forecast_28"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3be3d4",
   "metadata": {},
   "source": [
    "## LTSM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b0e1d7",
   "metadata": {},
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a41cac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the conditions for the new columns\n",
    "df_tweets['raw_sentiment_negative'] = df_tweets['raw_sentiment_classification'].apply(lambda x: 1 if x == 'Negative' else 0)\n",
    "df_tweets['raw_sentiment_positive'] = df_tweets['raw_sentiment_classification'].apply(lambda x: 1 if x == 'Positive' else 0)\n",
    "\n",
    "df_tweets['processed_sentiment_negative'] = df_tweets['processed_sentiment_classification'].apply(lambda x: 1 if x == 'Negative' else 0)\n",
    "df_tweets['processed_sentiment_positive'] = df_tweets['processed_sentiment_classification'].apply(lambda x: 1 if x == 'Positive' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cf0007a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>processed_text</th>\n",
       "      <th>raw_sentiment</th>\n",
       "      <th>raw_sentiment_classification</th>\n",
       "      <th>processed_sentiment</th>\n",
       "      <th>processed_sentiment_classification</th>\n",
       "      <th>sentiment_difference</th>\n",
       "      <th>raw_sentiment_negative</th>\n",
       "      <th>raw_sentiment_positive</th>\n",
       "      <th>processed_sentiment_negative</th>\n",
       "      <th>processed_sentiment_positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-04-06 22:19:45</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>switchfoot http awww bummer shoulda got david ...</td>\n",
       "      <td>-0.0173</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.3818</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.3645</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-06 22:19:49</th>\n",
       "      <td>1</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset ca update facebook texting might cry res...</td>\n",
       "      <td>-0.7500</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.7269</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.0231</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-06 22:19:53</th>\n",
       "      <td>2</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>kenichan dived many time ball managed save 50 ...</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-06 22:19:57</th>\n",
       "      <td>3</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feel itchy like fire</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.2500</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-06 22:19:57</th>\n",
       "      <td>4</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>nationwideclass behaving mad ca see</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>-0.4939</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0  \\\n",
       "date                              \n",
       "2009-04-06 22:19:45           0   \n",
       "2009-04-06 22:19:49           1   \n",
       "2009-04-06 22:19:53           2   \n",
       "2009-04-06 22:19:57           3   \n",
       "2009-04-06 22:19:57           4   \n",
       "\n",
       "                                                                  text  \\\n",
       "date                                                                     \n",
       "2009-04-06 22:19:45  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "2009-04-06 22:19:49  is upset that he can't update his Facebook by ...   \n",
       "2009-04-06 22:19:53  @Kenichan I dived many times for the ball. Man...   \n",
       "2009-04-06 22:19:57    my whole body feels itchy and like its on fire    \n",
       "2009-04-06 22:19:57  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                                        processed_text  \\\n",
       "date                                                                     \n",
       "2009-04-06 22:19:45  switchfoot http awww bummer shoulda got david ...   \n",
       "2009-04-06 22:19:49  upset ca update facebook texting might cry res...   \n",
       "2009-04-06 22:19:53  kenichan dived many time ball managed save 50 ...   \n",
       "2009-04-06 22:19:57                    whole body feel itchy like fire   \n",
       "2009-04-06 22:19:57                nationwideclass behaving mad ca see   \n",
       "\n",
       "                     raw_sentiment raw_sentiment_classification  \\\n",
       "date                                                              \n",
       "2009-04-06 22:19:45        -0.0173                     Negative   \n",
       "2009-04-06 22:19:49        -0.7500                     Negative   \n",
       "2009-04-06 22:19:53         0.4939                     Negative   \n",
       "2009-04-06 22:19:57        -0.2500                     Negative   \n",
       "2009-04-06 22:19:57        -0.4939                     Negative   \n",
       "\n",
       "                     processed_sentiment processed_sentiment_classification  \\\n",
       "date                                                                          \n",
       "2009-04-06 22:19:45              -0.3818                           Negative   \n",
       "2009-04-06 22:19:49              -0.7269                           Negative   \n",
       "2009-04-06 22:19:53               0.4939                           Negative   \n",
       "2009-04-06 22:19:57              -0.2500                           Negative   \n",
       "2009-04-06 22:19:57              -0.4939                           Negative   \n",
       "\n",
       "                     sentiment_difference  raw_sentiment_negative  \\\n",
       "date                                                                \n",
       "2009-04-06 22:19:45                0.3645                       1   \n",
       "2009-04-06 22:19:49               -0.0231                       1   \n",
       "2009-04-06 22:19:53                0.0000                       1   \n",
       "2009-04-06 22:19:57                0.0000                       1   \n",
       "2009-04-06 22:19:57                0.0000                       1   \n",
       "\n",
       "                     raw_sentiment_positive  processed_sentiment_negative  \\\n",
       "date                                                                        \n",
       "2009-04-06 22:19:45                       0                             1   \n",
       "2009-04-06 22:19:49                       0                             1   \n",
       "2009-04-06 22:19:53                       0                             1   \n",
       "2009-04-06 22:19:57                       0                             1   \n",
       "2009-04-06 22:19:57                       0                             1   \n",
       "\n",
       "                     processed_sentiment_positive  \n",
       "date                                               \n",
       "2009-04-06 22:19:45                             0  \n",
       "2009-04-06 22:19:49                             0  \n",
       "2009-04-06 22:19:53                             0  \n",
       "2009-04-06 22:19:57                             0  \n",
       "2009-04-06 22:19:57                             0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the dataset was updated correctly\n",
    "df_tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203614c1",
   "metadata": {},
   "source": [
    "We need numerical sentiment classification in order to be able to run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e06d34ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all entries in 'processed_text' are strings and handle missing values\n",
    "df_tweets['processed_text'] = df_tweets['processed_text'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf994a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'processed_sentiment' is the target variable for time-series forecasting\n",
    "series = df_tweets['processed_sentiment']\n",
    "texts = df_tweets['processed_text'].astype(str).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b96b3ea",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e4168fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of text_vectors: (1600000, 1000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Vectorize the text data with reduced features\n",
    "vectorizer = TfidfVectorizer(max_features=1000)  # Reduce max_features to manage memory\n",
    "text_vectors = vectorizer.fit_transform(texts)  # Keep it as a sparse matrix\n",
    "\n",
    "print(\"Shape of text_vectors:\", text_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79116e8f",
   "metadata": {},
   "source": [
    "### Combine Text Vectors with Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "62eec917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the sentiment data\n",
    "scaler = MinMaxScaler()\n",
    "series_scaled = scaler.fit_transform(series.values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ed36fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create sequences with text vectors and sentiment values\n",
    "def create_sequences_with_text(data, text_vectors, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sentiment_seq = data[i:i + seq_length]\n",
    "        text_vector = text_vectors[i + seq_length].toarray()\n",
    "        combined_seq = np.hstack((sentiment_seq.flatten(), text_vector.flatten()))\n",
    "        X.append(combined_seq)\n",
    "        y.append(data[i + seq_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa85b1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences\n",
    "seq_length = 5\n",
    "X, y = create_sequences_with_text(series_scaled, text_vectors, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57f4db57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (1279996, 1005)\n",
      "Shape of y_train: (1279996, 1)\n",
      "Shape of X_test: (319999, 1005)\n",
      "Shape of y_test: (319999, 1)\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(X) * split_ratio)\n",
    "X_train, y_train = X[:split_index], y[:split_index]\n",
    "X_test, y_test = X[split_index:], y[split_index:]\n",
    "\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703360e7",
   "metadata": {},
   "source": [
    "### Build and Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "382c3cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\Clara\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "20000/20000 [==============================] - 37s 2ms/step - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 2/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0108 - val_loss: 0.0084\n",
      "Epoch 3/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0107 - val_loss: 0.0082\n",
      "Epoch 4/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0106 - val_loss: 0.0082\n",
      "Epoch 5/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0105 - val_loss: 0.0081\n",
      "Epoch 6/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 7/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 8/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 9/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0105 - val_loss: 0.0080\n",
      "Epoch 10/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 11/50\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 12/50\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 13/50\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 14/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 15/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 16/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 17/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 18/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 19/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 20/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 21/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 22/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 23/50\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 24/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 25/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 26/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 27/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 28/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0085\n",
      "Epoch 29/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 30/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 31/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 32/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 33/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 34/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 35/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 36/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 37/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 38/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 39/50\n",
      "20000/20000 [==============================] - 32s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 40/50\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 41/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0079\n",
      "Epoch 42/50\n",
      "20000/20000 [==============================] - 28s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "20000/20000 [==============================] - 29s 1ms/step - loss: 0.0104 - val_loss: 0.0080\n",
      "Epoch 44/50\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.0104 - val_loss: 0.0083\n",
      "Epoch 45/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 46/50\n",
      "20000/20000 [==============================] - 30s 1ms/step - loss: 0.0104 - val_loss: 0.0081\n",
      "Epoch 47/50\n",
      "20000/20000 [==============================] - 30s 2ms/step - loss: 0.0104 - val_loss: 0.0089\n",
      "Epoch 48/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 49/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0104 - val_loss: 0.0086\n",
      "Epoch 50/50\n",
      "20000/20000 [==============================] - 31s 2ms/step - loss: 0.0104 - val_loss: 0.0080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23c6e63fb10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c044761",
   "metadata": {},
   "source": [
    "### Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b8eb224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000/40000 [==============================] - 31s 763us/step\n",
      "10000/10000 [==============================] - 9s 901us/step\n",
      "Train RMSE: 0.19407007805740084\n",
      "Test RMSE: 0.17888239695059494\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Invert predictions to original scale\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate RMSE\n",
    "train_rmse = np.sqrt(mean_squared_error(y_train_inv, train_predict))\n",
    "test_rmse = np.sqrt(mean_squared_error(y_test_inv, test_predict))\n",
    "print(\"Train RMSE:\", train_rmse)\n",
    "print(\"Test RMSE:\", test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b12df55",
   "metadata": {},
   "source": [
    "### Make Forecast for 1 Day, 3 Days, 7 Days and 1 month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "54716b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1\n",
      "Shape of sentiment_seq: (5, 1)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 1\n",
      "Shape of sentiment_seq: (5, 1)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 2\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 3\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 1\n",
      "Shape of sentiment_seq: (5, 1)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 2\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 3\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Step: 4\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 5\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 6\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 7\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 1\n",
      "Shape of sentiment_seq: (5, 1)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 2\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 3\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 4\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 5\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Step: 6\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Step: 7\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Step: 8\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Step: 9\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 10\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 11\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Step: 12\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Step: 13\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 14\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Step: 15\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 16\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 17\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 18\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "Step: 19\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Step: 20\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 21\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 22\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Step: 23\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 24\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 25\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 26\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "Step: 27\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Step: 28\n",
      "Shape of sentiment_seq: (5,)\n",
      "Shape of text_vector: (1, 1000)\n",
      "Shape of combined_input before reshape: (1005,)\n",
      "Shape of combined_input after reshape: (1, 1005)\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1-day forecast LSTM: [0.6508354]\n",
      "3-day forecast LSTM: [0.6508354  0.40439156 0.3759354 ]\n",
      "7-day forecast LSTM: [0.6508354  0.40439156 0.3759354  0.5760596  0.66861093 0.6693103\n",
      " 0.6695662 ]\n",
      "28-day forecast LSTM: [0.6508354  0.40439156 0.3759354  0.5760596  0.66861093 0.6693103\n",
      " 0.6695662  0.6720654  0.67476636 0.67566335 0.6757275  0.6757876\n",
      " 0.6758451  0.6758794  0.6758896  0.67589164 0.6758932  0.67589414\n",
      " 0.6758946  0.67589474 0.67589474 0.67589486 0.67589486 0.67589486\n",
      " 0.67589486 0.67589486 0.67589486 0.67589486]\n"
     ]
    }
   ],
   "source": [
    "# Function to forecast future values with debugging prints\n",
    "def forecast(model, data, text_vectors, seq_length, steps):\n",
    "    forecast_data = data[-seq_length:]\n",
    "    forecasts = []\n",
    "    for i in range(steps):\n",
    "        sentiment_seq = forecast_data[-seq_length:]\n",
    "        \n",
    "        # Correct index calculation for text_vector\n",
    "        text_index = len(data) - seq_length + i\n",
    "        if text_index >= text_vectors.shape[0]:\n",
    "            text_index = text_vectors.shape[0] - 1\n",
    "        text_vector = text_vectors[text_index].toarray()\n",
    "        \n",
    "        combined_input = np.hstack((sentiment_seq.flatten(), text_vector.flatten()))\n",
    "        \n",
    "        # Print shapes for debugging\n",
    "        print(\"Step:\", i + 1)\n",
    "        print(\"Shape of sentiment_seq:\", sentiment_seq.shape)\n",
    "        print(\"Shape of text_vector:\", text_vector.shape)\n",
    "        print(\"Shape of combined_input before reshape:\", combined_input.shape)\n",
    "        \n",
    "        combined_input = combined_input.reshape(1, -1)  # Ensure the input shape is correct\n",
    "        \n",
    "        # Print shape after reshaping\n",
    "        print(\"Shape of combined_input after reshape:\", combined_input.shape)\n",
    "        \n",
    "        prediction = model.predict(combined_input)\n",
    "        forecast_data = np.append(forecast_data[1:], prediction)\n",
    "        forecasts.append(prediction)\n",
    "    return np.array(forecasts).reshape(-1, 1)  # Ensure the output is 2D\n",
    "\n",
    "# Forecast for 1 day, 3 days, 7 days, and 28 days\n",
    "forecasts_1_day_LSTM = forecast(model, series_scaled, text_vectors, seq_length, 1)\n",
    "forecasts_3_days_LSTM = forecast(model, series_scaled, text_vectors, seq_length, 3)\n",
    "forecasts_7_days_LSTM = forecast(model, series_scaled, text_vectors, seq_length, 7)\n",
    "forecasts_28_days_LSTM = forecast(model, series_scaled, text_vectors, seq_length, 28)\n",
    "\n",
    "# Invert forecasts to original scale\n",
    "forecasts_1_day_LSTM = scaler.inverse_transform(forecasts_1_day_LSTM)\n",
    "forecasts_3_days_LSTM = scaler.inverse_transform(forecasts_3_days_LSTM)\n",
    "forecasts_7_days_LSTM = scaler.inverse_transform(forecasts_7_days_LSTM)\n",
    "forecasts_28_days_LSTM = scaler.inverse_transform(forecasts_28_days_LSTM)\n",
    "\n",
    "print(\"1-day forecast LSTM:\", forecasts_1_day_LSTM.flatten())\n",
    "print(\"3-day forecast LSTM:\", forecasts_3_days_LSTM.flatten())\n",
    "print(\"7-day forecast LSTM:\", forecasts_7_days_LSTM.flatten())\n",
    "print(\"28-day forecast LSTM:\", forecasts_28_days_LSTM.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b334f3",
   "metadata": {},
   "source": [
    "###  Visualize and Report Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a86ab9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f0081be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23caf319050>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app_arima = dash.Dash(__name__)\n",
    "\n",
    "app_arima.layout = html.Div([\n",
    "    html.H1(\"ARIMA Model Forecasting Dashboard\"),\n",
    "    dcc.Graph(\n",
    "        id='arima-forecast',\n",
    "        figure={\n",
    "            'data': [\n",
    "                go.Scatter(x=list(range(len(series))), y=series, mode='lines', name='Actual'),\n",
    "                go.Scatter(x=list(range(len(series), len(series) + 1)), y=arima_forecast_1, mode='lines', name='1-step Forecast'),\n",
    "                go.Scatter(x=list(range(len(series), len(series) + 3)), y=arima_forecast_3, mode='lines', name='3-step Forecast'),\n",
    "                go.Scatter(x=list(range(len(series), len(series) + 7)), y=arima_forecast_7, mode='lines', name='7-step Forecast'),\n",
    "                go.Scatter(x=list(range(len(series), len(series) + 28)), y=arima_forecast_28, mode='lines', name='28-step Forecast')\n",
    "            ],\n",
    "            'layout': go.Layout(title='ARIMA Forecasts', xaxis={'title': 'Time'}, yaxis={'title': 'Sentiment'})\n",
    "        }\n",
    "    ),\n",
    "    html.P(f\"RMSE (1-step): {arima_rmse_1}\"),\n",
    "    html.P(f\"RMSE (3-step): {arima_rmse_3}\"),\n",
    "    html.P(f\"RMSE (7-step): {arima_rmse_7}\"),\n",
    "    html.P(f\"RMSE (28-step): {arima_rmse_28}\")\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app_arima.run_server(debug=True, port=8050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0ae4406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = {\n",
    "    'loss': [0.0128, 0.0108, 0.0107, 0.0106, 0.0105, 0.0105, 0.0105, 0.0105, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104, 0.0104],\n",
    "    'val_loss': [0.0087, 0.0084, 0.0082, 0.0082, 0.0082, 0.0080, 0.0080, 0.0080, 0.0079, 0.0079, 0.0080, 0.0080, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081, 0.0081]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93d7efe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (1-day): 0.13546542629029545\n",
      "RMSE (3-day): 0.32411547594409457\n",
      "RMSE (7-day): 0.2724084276585802\n",
      "RMSE (28-day): 0.1611497658126404\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate RMSE\n",
    "def calculate_rmse(actual, predicted):\n",
    "    return np.sqrt(mean_squared_error(actual, predicted))\n",
    "\n",
    "# Assuming you have the following data:\n",
    "# series_scaled - the actual data\n",
    "# forecasts_1_day_LSTM, forecasts_3_days_LSTM, forecasts_7_days_LSTM, forecasts_28_days_LSTM - predicted data for different horizons\n",
    "\n",
    "# Extract the relevant portions of the series_scaled data for comparison\n",
    "actual_1_day = series_scaled[-len(forecasts_1_day_LSTM):]\n",
    "actual_3_days = series_scaled[-len(forecasts_3_days_LSTM):]\n",
    "actual_7_days = series_scaled[-len(forecasts_7_days_LSTM):]\n",
    "actual_28_days = series_scaled[-len(forecasts_28_days_LSTM):]\n",
    "\n",
    "# Calculate RMSE for each forecast horizon\n",
    "lstm_rmse_1 = calculate_rmse(actual_1_day, forecasts_1_day_LSTM)\n",
    "lstm_rmse_3 = calculate_rmse(actual_3_days, forecasts_3_days_LSTM)\n",
    "lstm_rmse_7 = calculate_rmse(actual_7_days, forecasts_7_days_LSTM)\n",
    "lstm_rmse_28 = calculate_rmse(actual_28_days, forecasts_28_days_LSTM)\n",
    "\n",
    "print(f\"RMSE (1-day): {lstm_rmse_1}\")\n",
    "print(f\"RMSE (3-day): {lstm_rmse_3}\")\n",
    "print(f\"RMSE (7-day): {lstm_rmse_7}\")\n",
    "print(f\"RMSE (28-day): {lstm_rmse_28}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea7bf34c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8051/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23caf42dcd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app_lstm = Dash(__name__)\n",
    "\n",
    "app_lstm.layout = html.Div([\n",
    "    html.H1(\"LSTM Model Forecasting Dashboard\"),\n",
    "    dcc.Graph(\n",
    "        id='lstm-training',\n",
    "        figure={\n",
    "            'data': [\n",
    "                go.Scatter(x=list(range(len(history['loss']))), y=history['loss'], mode='lines', name='Training Loss'),\n",
    "                go.Scatter(x=list(range(len(history['val_loss']))), y=history['val_loss'], mode='lines', name='Validation Loss')\n",
    "            ],\n",
    "            'layout': go.Layout(title='LSTM Training and Validation Loss', xaxis={'title': 'Epochs'}, yaxis={'title': 'Loss'})\n",
    "        }\n",
    "    ),\n",
    "    dcc.Graph(\n",
    "        id='lstm-forecast',\n",
    "        figure={\n",
    "            'data': [\n",
    "                go.Scatter(x=list(range(len(series_scaled) - len(series_scaled[-1:]), len(series_scaled))), y=series_scaled[-1:].flatten(), mode='lines', name='Actual'),\n",
    "                go.Scatter(x=list(range(len(series_scaled) - len(series_scaled[-1:]), len(series_scaled) - len(series_scaled[-1:]) + 1)), y=forecasts_1_day_LSTM.flatten(), mode='lines', name='1-day Forecast'),\n",
    "                go.Scatter(x=list(range(len(series_scaled) - len(series_scaled[-1:]), len(series_scaled) - len(series_scaled[-1:]) + 3)), y=forecasts_3_days_LSTM.flatten(), mode='lines', name='3-day Forecast'),\n",
    "                go.Scatter(x=list(range(len(series_scaled) - len(series_scaled[-1:]), len(series_scaled) - len(series_scaled[-1:]) + 7)), y=forecasts_7_days_LSTM.flatten(), mode='lines', name='7-day Forecast'),\n",
    "                go.Scatter(x=list(range(len(series_scaled) - len(series_scaled[-1:]), len(series_scaled) - len(series_scaled[-1:]) + 28)), y=forecasts_28_days_LSTM.flatten(), mode='lines', name='28-day Forecast')\n",
    "            ],\n",
    "            'layout': go.Layout(title='LSTM Forecasts', xaxis={'title': 'Time'}, yaxis={'title': 'Sentiment'})\n",
    "        }\n",
    "    ),\n",
    "    html.P(f\"RMSE (1-day): {lstm_rmse_1}\"),\n",
    "    html.P(f\"RMSE (3-day): {lstm_rmse_3}\"),\n",
    "    html.P(f\"RMSE (7-day): {lstm_rmse_7}\"),\n",
    "    html.P(f\"RMSE (28-day): {lstm_rmse_28}\")\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app_lstm.run_server(debug=True, port=8051)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3aa2eb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dash import Dash, html, dcc\n",
    "\n",
    "# Sampled Data\n",
    "sample_rate = 1000  # Adjust this number to sample less/more data points\n",
    "sampled_indices = np.arange(0, len(series), sample_rate)\n",
    "sampled_series = series[sampled_indices]\n",
    "sampled_arima_forecast_1 = arima_forecast_1[:len(sampled_indices)]\n",
    "sampled_arima_forecast_3 = arima_forecast_3[:len(sampled_indices)]\n",
    "sampled_arima_forecast_7 = arima_forecast_7[:len(sampled_indices)]\n",
    "sampled_arima_forecast_28 = arima_forecast_28[:len(sampled_indices)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1ac1008b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23ca5e9a4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dash import Dash, html, dcc\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "# Assuming series, sampled_indices, sampled_series, sampled_arima_forecast_1, sampled_arima_forecast_3, sampled_arima_forecast_7, sampled_arima_forecast_28, \n",
    "# arima_rmse_1, arima_rmse_3, arima_rmse_7, arima_rmse_28 are already defined\n",
    "\n",
    "app_arima_1 = Dash(__name__)\n",
    "\n",
    "app_arima_1.layout = html.Div([\n",
    "    html.H1(\"ARIMA Model Forecasting Dashboard (Sampled Data)\"),\n",
    "    dcc.Graph(\n",
    "        id='arima-forecast-1',\n",
    "        figure={\n",
    "            'data': [\n",
    "                go.Scatter(x=sampled_indices, y=sampled_series, mode='lines', name='Actual'),\n",
    "                go.Scatter(x=sampled_indices, y=sampled_arima_forecast_1, mode='lines', name='1-step Forecast', line=dict(dash='dash')),\n",
    "                go.Scatter(x=sampled_indices, y=sampled_arima_forecast_3, mode='lines', name='3-step Forecast', line=dict(dash='dot')),\n",
    "                go.Scatter(x=sampled_indices, y=sampled_arima_forecast_7, mode='lines', name='7-step Forecast', line=dict(dash='longdash')),\n",
    "                go.Scatter(x=sampled_indices, y=sampled_arima_forecast_28, mode='lines', name='28-step Forecast', line=dict(dash='dashdot'))\n",
    "            ],\n",
    "            'layout': go.Layout(title='ARIMA Forecasts (Sampled Data)', xaxis={'title': 'Time'}, yaxis={'title': 'Sentiment'})\n",
    "        }\n",
    "    ),\n",
    "    html.P(f\"RMSE (1-step): {arima_rmse_1}\"),\n",
    "    html.P(f\"RMSE (3-step): {arima_rmse_3}\"),\n",
    "    html.P(f\"RMSE (7-step): {arima_rmse_7}\"),\n",
    "    html.P(f\"RMSE (28-step): {arima_rmse_28}\")\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app_arima_1.run_server(port=8052, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9729b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoomed-In Data\n",
    "zoom_start = -500\n",
    "zoomed_series = series[zoom_start:]\n",
    "zoomed_arima_forecast_1 = arima_forecast_1[zoom_start:]\n",
    "zoomed_arima_forecast_3 = arima_forecast_3[zoom_start:]\n",
    "zoomed_arima_forecast_7 = arima_forecast_7[zoom_start:]\n",
    "zoomed_arima_forecast_28 = arima_forecast_28[zoom_start:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2ccfba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8052/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23ca5e71dd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "app_arima_2 = Dash(__name__)\n",
    "\n",
    "app_arima_2.layout = html.Div([\n",
    "    html.H1(\"ARIMA Model Forecasting Dashboard (Zoomed-In Data)\"),\n",
    "    dcc.Graph(\n",
    "        id='arima-forecast-2',\n",
    "        figure={\n",
    "            'data': [\n",
    "                go.Scatter(x=list(range(len(zoomed_series))), y=zoomed_series, mode='lines', name='Actual'),\n",
    "                go.Scatter(x=list(range(len(zoomed_series), len(zoomed_series) + 1)), y=zoomed_arima_forecast_1, mode='lines', name='1-step Forecast', line=dict(dash='dash')),\n",
    "                go.Scatter(x=list(range(len(zoomed_series), len(zoomed_series) + 3)), y=zoomed_arima_forecast_3, mode='lines', name='3-step Forecast', line=dict(dash='dot')),\n",
    "                go.Scatter(x=list(range(len(zoomed_series), len(zoomed_series) + 7)), y=zoomed_arima_forecast_7, mode='lines', name='7-step Forecast', line=dict(dash='longdash')),\n",
    "                go.Scatter(x=list(range(len(zoomed_series), len(zoomed_series) + 28)), y=zoomed_arima_forecast_28, mode='lines', name='28-step Forecast', line=dict(dash='dashdot'))\n",
    "            ],\n",
    "            'layout': go.Layout(title='ARIMA Forecasts (Zoomed-In Data)', xaxis={'title': 'Time'}, yaxis={'title': 'Sentiment'})\n",
    "        }\n",
    "    ),\n",
    "    html.P(f\"RMSE (1-step): {arima_rmse_1}\"),\n",
    "    html.P(f\"RMSE (3-step): {arima_rmse_3}\"),\n",
    "    html.P(f\"RMSE (7-step): {arima_rmse_7}\"),\n",
    "    html.P(f\"RMSE (28-step): {arima_rmse_28}\")\n",
    "])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app_arima_2.run_server(port=8052, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226973c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
